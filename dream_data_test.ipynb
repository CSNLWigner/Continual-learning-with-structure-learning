{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import helper\n",
        "\n",
        "import matplotlib as mpl\n",
        "import pickle\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from graphviz import Digraph\n",
        "import itertools\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.stats import multivariate_normal"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:21:31.158Z",
          "iopub.execute_input": "2021-04-01T09:21:31.166Z",
          "shell.execute_reply": "2021-04-01T09:21:31.700Z",
          "iopub.status.idle": "2021-04-01T09:21:31.710Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate data from 2 tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sokatmondo_adat():\n",
        "  alpha = 90 #x-esek eloszor\n",
        "  sigma_r = .3\n",
        "  gamma = helper.gamma_from_alpha(alpha)\n",
        "  Tx = 3\n",
        "  z_prior = tfd.MultivariateNormalDiag(loc=[-1,1], scale_diag=[.3,.3]);\n",
        "  z = np.array(z_prior.sample(Tx))\n",
        "  r_noise = tfd.Normal(0, .001).sample(Tx)\n",
        "  r_mean = tf.reduce_sum(tf.multiply(gamma,z),1)\n",
        "  r = r_mean + r_noise\n",
        "  datax = {'z':z,'r':r}\n",
        "\n",
        "  alpha = 0 #utana y-osok\n",
        "  gamma = helper.gamma_from_alpha(alpha)\n",
        "  Ty = 3\n",
        "  z_prior = tfd.MultivariateNormalDiag(loc=[-1,1], scale_diag=[.3,.3]);\n",
        "  z = np.array(z_prior.sample(Ty))\n",
        "  r_noise = tfd.Normal(0, .001).sample(Ty)\n",
        "  r_mean = tf.reduce_sum(tf.multiply(gamma,z),1)\n",
        "  r = r_mean + r_noise\n",
        "  datay = {'z':z,'r':r}\n",
        "\n",
        "  data = concatenate_data(datax, datay)\n",
        "  z = data['z']\n",
        "  r = np.array(data['r'])\n",
        "\n",
        "  xylabels = ['x']*Tx + ['y']*Ty\n",
        "  return z, r, xylabels\n",
        "\n",
        "def concatenate_data(data1, data2):\n",
        "  z = np.concatenate((data1['z'], data2['z']), 0)\n",
        "  r = np.concatenate((np.array(data1['r']), np.array(data2['r'])))\n",
        "  return {'z': z, 'r': r}\n",
        "\n",
        "def plot_data_xy_labels(data, labels):\n",
        "    plt.scatter(*data['z'].T,c=data['r'])\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('z_1')\n",
        "    plt.ylabel('z_2')\n",
        "    plt.axhline(y = 0)\n",
        "    plt.axvline(x = 0)\n",
        "    for label, x, y in zip(labels, data['z'][:, 0], data['z'][:, 1]):\n",
        "        plt.annotate(\n",
        "            label,\n",
        "            xy=(x, y), xytext=(-20, 20),\n",
        "            textcoords='offset points', ha='right', va='bottom',\n",
        "            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
        "            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:21:32.091Z",
          "iopub.execute_input": "2021-04-01T09:21:32.097Z",
          "iopub.status.idle": "2021-04-01T09:21:32.108Z",
          "shell.execute_reply": "2021-04-01T09:21:32.116Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2**2 # particleok szama\n",
        "sigma_r = .3\n",
        "z, r, xylabels = sokatmondo_adat()\n",
        "data1 = {'z':z, 'r':r}\n",
        "plot_data_xy_labels(data1, xylabels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:21:34.927Z",
          "iopub.execute_input": "2021-04-01T09:21:34.936Z",
          "iopub.status.idle": "2021-04-01T09:21:36.881Z",
          "shell.execute_reply": "2021-04-01T09:21:36.942Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit 2D 1 task model [(?)](https://www.notion.so/EM-meeting-344e2ac8dfdb45bb916d844de3cd4ca5#5a462ae58c1a47339f0e0cf0c01a4e41)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posterior_params = helper.gamma_posterior_analytic(data1['z'], data1['r'], sigma_r, Sigma_0=10*np.eye(2))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:48:24.750Z",
          "iopub.execute_input": "2021-04-01T09:48:24.814Z",
          "iopub.status.idle": "2021-04-01T09:48:24.824Z",
          "shell.execute_reply": "2021-04-01T09:48:24.831Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posterior = tfd.MultivariateNormalFullCovariance(loc=posterior_params[0], covariance_matrix=posterior_params[1])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:48:26.792Z",
          "iopub.execute_input": "2021-04-01T09:48:26.802Z",
          "iopub.status.idle": "2021-04-01T09:48:26.815Z",
          "shell.execute_reply": "2021-04-01T09:48:26.821Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = posterior.sample(300)\n",
        "sns.kdeplot(x=samples[:, 0], y=samples[:, 1])\n",
        "plt.scatter(x=samples[:, 0], y=samples[:, 1])\n",
        "samples = posterior.sample(10)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:21:38.315Z",
          "iopub.execute_input": "2021-04-01T09:21:38.324Z",
          "shell.execute_reply": "2021-04-01T09:21:38.731Z",
          "iopub.status.idle": "2021-04-01T09:21:38.744Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate dream data from posterior"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_from_posterior_samples(N=100, gamma=0, z_prior_type='uniform', sigma_z_prior=1, r_bias=0, sigma_reward=0.1, sigma_bias=0):\n",
        "    if z_prior_type == 'normal':\n",
        "        z_prior = tfd.MultivariateNormalDiag(loc=[0,0], scale_diag=[sigma_z_prior,sigma_z_prior]);\n",
        "    elif z_prior_type == 'uniform':\n",
        "        z_prior = tfd.Uniform([0,0],[sigma_z_prior,sigma_z_prior])\n",
        "\n",
        "    z = np.array(z_prior.sample(N))\n",
        "\n",
        "    r_noise = tfd.Normal(0, sigma_reward).sample(N)\n",
        "    r_mean = tf.cast(tf.reduce_sum(tf.multiply(gamma,z),1),dtype=tf.float32) + r_bias\n",
        "    r = r_mean + r_noise\n",
        "\n",
        "    return z[0],r[0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T09:21:40.281Z",
          "iopub.execute_input": "2021-04-01T09:21:40.289Z",
          "iopub.status.idle": "2021-04-01T09:21:40.298Z",
          "shell.execute_reply": "2021-04-01T09:21:40.305Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dream_data_from_posterior_samples(samples):\n",
        "  z_samples = []\n",
        "  r_samples = []\n",
        "\n",
        "  for gamma_sample in samples:\n",
        "      # generate a single datapoint for each gamma sample\n",
        "      z,r = generate_data_from_posterior_samples(N=1, gamma=gamma_sample, z_prior_type='uniform', sigma_reward=0.1)\n",
        "      z_samples.append(z)\n",
        "      r_samples.append(r)\n",
        "\n",
        "  z_samples = np.array(z_samples)\n",
        "  r_samples = np.array(r_samples)\n",
        "\n",
        "  return {'z': np.array(z_samples), 'r': np.array(r_samples)}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T10:20:28.196Z",
          "iopub.execute_input": "2021-04-01T10:20:28.206Z",
          "iopub.status.idle": "2021-04-01T10:20:28.221Z",
          "shell.execute_reply": "2021-04-01T10:20:28.229Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dream_data = generate_dream_data_from_posterior_samples(samples)\n",
        "helper.plot_data(dream_data, labels=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T10:20:42.060Z",
          "iopub.execute_input": "2021-04-01T10:20:42.067Z",
          "iopub.status.idle": "2021-04-01T10:20:42.257Z",
          "shell.execute_reply": "2021-04-01T10:20:42.249Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute mllh for 1 task and 2 task models on dream data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mllh on 2D 1 task model\n",
        "# there is one of these in helper and one of these defined in particle_filter.ipynb\n",
        "# helper.compute_log_mllh_by_gamma(z, r, gamma_samples, sigma_reward)\n",
        "helper.model_marginal_llh_analytic(dream_data['z'], dream_data['r'], sigma_r, Sigma_0=np.eye(2))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T10:26:43.051Z",
          "iopub.execute_input": "2021-04-01T10:26:43.056Z",
          "iopub.status.idle": "2021-04-01T10:26:43.068Z",
          "shell.execute_reply": "2021-04-01T10:26:43.074Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mllh on 2D 2 task model\n",
        "# these are from particle_filter.ipynb but is it correct to just mllh?\n",
        "\n",
        "from itertools import chain, combinations\n",
        "def powerset(iterable):\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "\n",
        "def model_marginal_llh_analytic(zs, rs, sigma_r, Sigma_0 = np.array([[1., 0.], [0., 1.]]), model = '2d'):\n",
        "    # this is the model marginal likelihood function\n",
        "    # it is validated through 'trial_nonorm_posterior_set_transformed'\n",
        "    # from that function the only step fowrad is to leave the normal in gamma (the gamma posterior) since gamma is marginalized out\n",
        "    if zs.size != 0:\n",
        "      T = np.size(zs,0)\n",
        "      if model == '2d':\n",
        "        assert not np.isscalar(Sigma_0), 'Sigma_0 must be a 2-dimensional array'\n",
        "        detSigma_0 = np.linalg.det(Sigma_0)\n",
        "        Sigma_i_star_invs = []\n",
        "        Sigma_i_invs = []\n",
        "        mu_is = []\n",
        "        y = 1/(2*np.pi)/np.sqrt(np.linalg.det(Sigma_0))\n",
        "        for t in range(T):\n",
        "            z = zs[t]\n",
        "            r = rs[t]\n",
        "            Sigma_i_star_inv = np.array([[z[0]**2/sigma_r**2, z[0]*z[1]/sigma_r**2],[z[0]*z[1]/sigma_r**2, z[1]**2/sigma_r**2]])\n",
        "            Sigma_i_star_invs.append(Sigma_i_star_inv)\n",
        "            if t==0:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + np.linalg.inv(Sigma_0)\n",
        "            else:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + Sigma_i_invs[t-1]\n",
        "            Sigma_i_invs.append(Sigma_i_inv)\n",
        "            Sigma_i = np.linalg.inv(Sigma_i_inv)\n",
        "            if t==0:\n",
        "                mu_i = Sigma_i.dot(z*r/sigma_r**2)\n",
        "            else:\n",
        "                mu_i = Sigma_i.dot(z*r/sigma_r**2 + Sigma_i_invs[t-1].dot(mu_is[t-1]))\n",
        "            mu_is.append(mu_i)\n",
        "            y = y * multivariate_normal.pdf(r, mean = 0, cov = sigma_r**2)\n",
        "        y = y / multivariate_normal.pdf(mu_i, mean = np.array([0,0]), cov = Sigma_i)\n",
        "      else:\n",
        "        '''\n",
        "        Sigma_0 is the standard deviation of the gamma prior\n",
        "        '''\n",
        "        assert np.isscalar(Sigma_0), 'Sigma_0 must be scalar'\n",
        "        if model == 'x':\n",
        "          integral_dim = 1\n",
        "        else:\n",
        "          integral_dim = 0\n",
        "\n",
        "        Sigma_i_star_invs = []\n",
        "        Sigma_i_invs = []\n",
        "        mu_is = []\n",
        "        y = 1/(np.sqrt(2*np.pi))/Sigma_0\n",
        "        for t in range(T):\n",
        "            z = zs[t]\n",
        "            r = rs[t]\n",
        "          \n",
        "            Sigma_i_star_inv = z[integral_dim]**2/sigma_r**2\n",
        "            Sigma_i_star_invs.append(Sigma_i_star_inv)\n",
        "            if t==0:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + 1/Sigma_0**2\n",
        "            else:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + Sigma_i_invs[t-1]\n",
        "            Sigma_i_invs.append(Sigma_i_inv)\n",
        "            Sigma_i = 1/Sigma_i_inv\n",
        "            if t==0:\n",
        "                mu_i = Sigma_i * z[integral_dim]*r/sigma_r**2\n",
        "            else:\n",
        "                mu_i = Sigma_i * (z[integral_dim]*r/sigma_r**2 + Sigma_i_invs[t-1]*mu_is[t-1])\n",
        "            mu_is.append(mu_i)\n",
        "            y = y * multivariate_normal.pdf(r, mean = 0, cov = sigma_r**2)\n",
        "        y = y / multivariate_normal.pdf(mu_i, mean = 0.0, cov = Sigma_i)\n",
        "\n",
        "      return y\n",
        "    else:\n",
        "      return 1.\n",
        "\n",
        "def model_marginal_llh_analytic_2x2D(z, r, sigma_r, Sigma_0_2D = np.array([[1., 0.], [0., 1.]]), verbose = True):\n",
        "  T = z.shape[0]\n",
        "  \n",
        "  indices = np.arange(T)\n",
        "  index_subsets = list(powerset(indices))\n",
        "\n",
        "  mmllh_accumulator = 0.\n",
        "  if verbose:\n",
        "    pbar = tf.keras.utils.Progbar(len(index_subsets))\n",
        "  for index_subset in index_subsets:\n",
        "    z1 = z[list(index_subset)]\n",
        "    r1 = r[list(index_subset)]\n",
        "    \n",
        "    complementer_subset = [item for item in indices if item not in index_subset]\n",
        "    \n",
        "    z2 = z[complementer_subset]\n",
        "    r2 = r[complementer_subset]\n",
        "    \n",
        "    mmllh_accumulator += model_marginal_llh_analytic(z1, r1, sigma_r, Sigma_0 = Sigma_0_2D, model = '2d') \\\n",
        "    * model_marginal_llh_analytic(z2, r2, sigma_r, Sigma_0 = Sigma_0_2D, model = '2d')\n",
        "    \n",
        "    if verbose:\n",
        "      pbar.add(1)\n",
        "      \n",
        "  mmllh_accumulator /= 2**T\n",
        "  return mmllh_accumulator"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T11:14:38.527Z",
          "iopub.execute_input": "2021-04-01T11:14:38.533Z",
          "iopub.status.idle": "2021-04-01T11:14:38.545Z",
          "shell.execute_reply": "2021-04-01T11:14:38.550Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_marginal_llh_analytic_2x2D(dream_data['z'], dream_data['r'], sigma_r, Sigma_0_2D = np.array([[1., 0.], [0., 1.]]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-01T11:14:39.554Z",
          "iopub.execute_input": "2021-04-01T11:14:39.560Z",
          "iopub.status.idle": "2021-04-01T11:14:41.391Z",
          "shell.execute_reply": "2021-04-01T11:14:41.396Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "argv": [
        "C:/Users/david/Anaconda3\\python.exe",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}