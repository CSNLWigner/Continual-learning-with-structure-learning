{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as tfd\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import helper\n",
        "\n",
        "import matplotlib as mpl\n",
        "import pickle\n",
        "from copy import deepcopy\n",
        "import time\n",
        "from graphviz import Digraph\n",
        "import itertools\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "N = 2**2 # particleok szama\n",
        "sigma_r = .3\n",
        "sig_r_model = .3\n",
        "\n",
        "Tx = 5\n",
        "Ty = 5\n",
        "EM_SIZE = 5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:19.900Z",
          "iopub.execute_input": "2021-04-07T13:06:19.908Z",
          "shell.execute_reply": "2021-04-07T13:06:20.266Z",
          "iopub.status.idle": "2021-04-07T13:06:20.217Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sokatmondo_adat(Tx=Tx,Ty=Ty):\n",
        "  alpha = 90 #x-esek eloszor\n",
        "  sigma_r = .3\n",
        "  gamma = helper.gamma_from_alpha(alpha)\n",
        "  #Tx = 3\n",
        "  z_prior = tfd.MultivariateNormalDiag(loc=[-1,1], scale_diag=[.3,.3]);\n",
        "  z = np.array(z_prior.sample(Tx))\n",
        "  r_noise = tfd.Normal(0, .001).sample(Tx)\n",
        "  r_mean = tf.reduce_sum(tf.multiply(gamma,z),1)\n",
        "  r = r_mean + r_noise\n",
        "  datax = {'z':z,'r':r}\n",
        "\n",
        "  alpha = 0 #utana y-osok\n",
        "  gamma = helper.gamma_from_alpha(alpha)\n",
        "  #Ty = 3\n",
        "  z_prior = tfd.MultivariateNormalDiag(loc=[-1,1], scale_diag=[.3,.3]);\n",
        "  z = np.array(z_prior.sample(Ty))\n",
        "  r_noise = tfd.Normal(0, .001).sample(Ty)\n",
        "  r_mean = tf.reduce_sum(tf.multiply(gamma,z),1)\n",
        "  r = r_mean + r_noise\n",
        "  datay = {'z':z,'r':r}\n",
        "\n",
        "  data = concatenate_data(datax, datay)\n",
        "  z = data['z']\n",
        "  r = np.array(data['r'])\n",
        "\n",
        "  xylabels = ['x']*Tx + ['y']*Ty\n",
        "  return z, r, xylabels\n",
        "\n",
        "def concatenate_data(data1, data2):\n",
        "  z = np.concatenate((data1['z'], data2['z']), 0)\n",
        "  r = np.concatenate((np.array(data1['r']), np.array(data2['r'])))\n",
        "  return {'z': z, 'r': r}\n",
        "\n",
        "def plot_data_xy_labels(data, labels):\n",
        "    plt.scatter(*data['z'].T,c=data['r'])\n",
        "    plt.gca().set_aspect('equal')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('z_1')\n",
        "    plt.ylabel('z_2')\n",
        "    plt.axhline(y = 0)\n",
        "    plt.axvline(x = 0)\n",
        "    for label, x, y in zip(labels, data['z'][:, 0], data['z'][:, 1]):\n",
        "        plt.annotate(\n",
        "            label,\n",
        "            xy=(x, y), xytext=(-20, 20),\n",
        "            textcoords='offset points', ha='right', va='bottom',\n",
        "            bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
        "            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:20.229Z",
          "iopub.execute_input": "2021-04-07T13:06:20.236Z",
          "iopub.status.idle": "2021-04-07T13:06:20.249Z",
          "shell.execute_reply": "2021-04-07T13:06:20.271Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z, r, xylabels = sokatmondo_adat(5,5)\n",
        "true_data = {'z':z, 'r':r}\n",
        "#plot_data_xy_labels(true_data, xylabels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:20.307Z",
          "iopub.execute_input": "2021-04-07T13:06:20.814Z",
          "iopub.status.idle": "2021-04-07T13:06:21.116Z",
          "shell.execute_reply": "2021-04-07T13:06:21.101Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data_xy_labels(true_data, xylabels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.125Z",
          "iopub.execute_input": "2021-04-07T13:06:21.131Z",
          "shell.execute_reply": "2021-04-07T13:06:21.566Z",
          "iopub.status.idle": "2021-04-07T13:06:21.499Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_x = {'z':true_data['z'][:Tx], 'r':true_data['r'][:Tx]}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.509Z",
          "iopub.execute_input": "2021-04-07T13:06:21.517Z",
          "iopub.status.idle": "2021-04-07T13:06:21.529Z",
          "shell.execute_reply": "2021-04-07T13:06:21.571Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data_xy_labels(data_x, xylabels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.539Z",
          "iopub.execute_input": "2021-04-07T13:06:21.546Z",
          "iopub.status.idle": "2021-04-07T13:06:21.780Z",
          "shell.execute_reply": "2021-04-07T13:06:21.895Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data_from_posterior_samples(N=100, gamma=0, z_prior_type='uniform', sigma_z_prior=1, r_bias=0, sigma_reward=0.1, sigma_bias=0):\n",
        "    if z_prior_type == 'normal':\n",
        "        z_prior = tfd.MultivariateNormalDiag(loc=[0,0], scale_diag=[sigma_z_prior,sigma_z_prior]);\n",
        "    elif z_prior_type == 'uniform':\n",
        "        z_prior = tfd.Uniform([0,0],[sigma_z_prior,sigma_z_prior])\n",
        "\n",
        "    z = np.array(z_prior.sample(N))\n",
        "\n",
        "    r_noise = tfd.Normal(0, sigma_reward).sample(N)\n",
        "    r_mean = tf.cast(tf.reduce_sum(tf.multiply(gamma,z),1),dtype=tf.float32) + r_bias\n",
        "    r = r_mean + r_noise\n",
        "\n",
        "    return z[0],r[0]\n",
        "  \n",
        "def generate_dream_data_from_posterior_samples(samples):\n",
        "  z_samples = []\n",
        "  r_samples = []\n",
        "\n",
        "  for gamma_sample in samples:\n",
        "      # generate a single datapoint for each gamma sample\n",
        "      z,r = generate_data_from_posterior_samples(N=1, gamma=gamma_sample, z_prior_type='uniform', sigma_reward=sig_r_model)\n",
        "      z_samples.append(z)\n",
        "      r_samples.append(r)\n",
        "\n",
        "  z_samples = np.array(z_samples)\n",
        "  r_samples = np.array(r_samples)\n",
        "\n",
        "  return {'z': np.array(z_samples), 'r': np.array(r_samples)}\n",
        "\n",
        "def generate_dream_data_set(posterior, T=10, N=2):\n",
        "  '''generates multiple dream data sets'''\n",
        "  dream_data_sets = []\n",
        "  for i in range(N):\n",
        "    samples = posterior.sample(T)\n",
        "    dream_data = generate_dream_data_from_posterior_samples(samples)\n",
        "    dream_data_sets.append(dream_data)\n",
        "  return dream_data_sets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.790Z",
          "iopub.execute_input": "2021-04-07T13:06:21.796Z",
          "iopub.status.idle": "2021-04-07T13:06:21.808Z",
          "shell.execute_reply": "2021-04-07T13:06:21.899Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute mllh for 1 task and 2 task models on dream data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mllh on 2D 2 task model\n",
        "# these are from particle_filter.ipynb but is it correct to just mllh?\n",
        "\n",
        "from itertools import chain, combinations\n",
        "def powerset(iterable):\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
        "\n",
        "def model_marginal_llh_analytic(zs, rs, sigma_r, Sigma_0 = np.array([[1., 0.], [0., 1.]]), model = '2d'):\n",
        "    # this is the model marginal likelihood function\n",
        "    # it is validated through 'trial_nonorm_posterior_set_transformed'\n",
        "    # from that function the only step fowrad is to leave the normal in gamma (the gamma posterior) since gamma is marginalized out\n",
        "    if zs.size != 0:\n",
        "      T = np.size(zs,0)\n",
        "      if model == '2d':\n",
        "        assert not np.isscalar(Sigma_0), 'Sigma_0 must be a 2-dimensional array'\n",
        "        detSigma_0 = np.linalg.det(Sigma_0)\n",
        "        Sigma_i_star_invs = []\n",
        "        Sigma_i_invs = []\n",
        "        mu_is = []\n",
        "        y = 1/(2*np.pi)/np.sqrt(np.linalg.det(Sigma_0))\n",
        "        for t in range(T):\n",
        "            z = zs[t]\n",
        "            r = rs[t]\n",
        "            Sigma_i_star_inv = np.array([[z[0]**2/sigma_r**2, z[0]*z[1]/sigma_r**2],[z[0]*z[1]/sigma_r**2, z[1]**2/sigma_r**2]])\n",
        "            Sigma_i_star_invs.append(Sigma_i_star_inv)\n",
        "            if t==0:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + np.linalg.inv(Sigma_0)\n",
        "            else:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + Sigma_i_invs[t-1]\n",
        "            Sigma_i_invs.append(Sigma_i_inv)\n",
        "            Sigma_i = np.linalg.inv(Sigma_i_inv)\n",
        "            if t==0:\n",
        "                mu_i = Sigma_i.dot(z*r/sigma_r**2)\n",
        "            else:\n",
        "                mu_i = Sigma_i.dot(z*r/sigma_r**2 + Sigma_i_invs[t-1].dot(mu_is[t-1]))\n",
        "            mu_is.append(mu_i)\n",
        "            y = y * multivariate_normal.pdf(r, mean = 0, cov = sigma_r**2)\n",
        "        y = y / multivariate_normal.pdf(mu_i, mean = np.array([0,0]), cov = Sigma_i)\n",
        "      else:\n",
        "        '''\n",
        "        Sigma_0 is the standard deviation of the gamma prior\n",
        "        '''\n",
        "        assert np.isscalar(Sigma_0), 'Sigma_0 must be scalar'\n",
        "        if model == 'x':\n",
        "          integral_dim = 1\n",
        "        else:\n",
        "          integral_dim = 0\n",
        "\n",
        "        Sigma_i_star_invs = []\n",
        "        Sigma_i_invs = []\n",
        "        mu_is = []\n",
        "        y = 1/(np.sqrt(2*np.pi))/Sigma_0\n",
        "        for t in range(T):\n",
        "            z = zs[t]\n",
        "            r = rs[t]\n",
        "          \n",
        "            Sigma_i_star_inv = z[integral_dim]**2/sigma_r**2\n",
        "            Sigma_i_star_invs.append(Sigma_i_star_inv)\n",
        "            if t==0:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + 1/Sigma_0**2\n",
        "            else:\n",
        "                Sigma_i_inv = Sigma_i_star_inv + Sigma_i_invs[t-1]\n",
        "            Sigma_i_invs.append(Sigma_i_inv)\n",
        "            Sigma_i = 1/Sigma_i_inv\n",
        "            if t==0:\n",
        "                mu_i = Sigma_i * z[integral_dim]*r/sigma_r**2\n",
        "            else:\n",
        "                mu_i = Sigma_i * (z[integral_dim]*r/sigma_r**2 + Sigma_i_invs[t-1]*mu_is[t-1])\n",
        "            mu_is.append(mu_i)\n",
        "            y = y * multivariate_normal.pdf(r, mean = 0, cov = sigma_r**2)\n",
        "        y = y / multivariate_normal.pdf(mu_i, mean = 0.0, cov = Sigma_i)\n",
        "\n",
        "      return y\n",
        "    else:\n",
        "      return 1.\n",
        "\n",
        "def model_marginal_llh_analytic_2x2D(z, r, sigma_r, Sigma_0_2D = np.array([[1., 0.], [0., 1.]]), verbose = True):\n",
        "  T = z.shape[0]\n",
        "  \n",
        "  indices = np.arange(T)\n",
        "  index_subsets = list(powerset(indices))\n",
        "\n",
        "  mmllh_accumulator = 0.\n",
        "  if verbose:\n",
        "    pbar = tf.keras.utils.Progbar(len(index_subsets))\n",
        "  for index_subset in index_subsets:\n",
        "    z1 = z[list(index_subset)]\n",
        "    r1 = r[list(index_subset)]\n",
        "    \n",
        "    complementer_subset = [item for item in indices if item not in index_subset]\n",
        "    \n",
        "    z2 = z[complementer_subset]\n",
        "    r2 = r[complementer_subset]\n",
        "    \n",
        "    mmllh_accumulator += model_marginal_llh_analytic(z1, r1, sigma_r, Sigma_0 = Sigma_0_2D, model = '2d') \\\n",
        "    * model_marginal_llh_analytic(z2, r2, sigma_r, Sigma_0 = Sigma_0_2D, model = '2d')\n",
        "    \n",
        "    if verbose:\n",
        "      pbar.add(1)\n",
        "      \n",
        "  mmllh_accumulator /= 2**T\n",
        "  return mmllh_accumulator"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.819Z",
          "iopub.execute_input": "2021-04-07T13:06:21.825Z",
          "iopub.status.idle": "2021-04-07T13:06:21.836Z",
          "shell.execute_reply": "2021-04-07T13:06:21.904Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_x = {'z':true_data['z'][:Tx], 'r':true_data['r'][:Tx]}\n",
        "data_EM = {'z':true_data['z'][Tx:Tx+EM_SIZE], 'r':true_data['r'][Tx:Tx+EM_SIZE]}\n",
        "data_fit = {'z':np.concatenate([data_x['z'], data_EM['z']]), 'r':np.concatenate([data_x['r'], data_EM['r']])}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.849Z",
          "iopub.execute_input": "2021-04-07T13:06:21.857Z",
          "iopub.status.idle": "2021-04-07T13:06:21.870Z",
          "shell.execute_reply": "2021-04-07T13:06:21.909Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit 2D 1 task model\n",
        "posterior_params = helper.gamma_posterior_analytic(data_fit['z'], data_fit['r'], sigma_r, Sigma_0=10*np.eye(2))\n",
        "posterior = tfd.MultivariateNormalFullCovariance(loc=posterior_params[0], covariance_matrix=posterior_params[1])\n",
        "\n",
        "# generate samples from gamma posterior\n",
        "samples = posterior.sample(10)\n",
        "\n",
        "# generate N dream data sets\n",
        "dreams = generate_dream_data_set(posterior, T=5, N=10)\n",
        "\n",
        "#append episodic memories to dreams\n",
        "\n",
        "dreams_plus_EM = []\n",
        "for dream in dreams:\n",
        "    dream_plus_EM = {'z':np.concatenate([dream['z'], data_EM['z']]), 'r':np.concatenate([dream['r'], data_EM['r']])}\n",
        "    dream_plus_EM = dreams_plus_EM.append(dream_plus_EM)\n",
        "dreams = dreams_plus_EM\n",
        "    \n",
        "# mllh on 2D 1 task model\n",
        "onetask_mllhs_dream = [helper.model_marginal_llh_analytic(dream['z'], dream['r'], sigma_r, Sigma_0=np.eye(2)) for dream in dreams]\n",
        "\n",
        "# mllh on 2D 2 task model\n",
        "twotask_mllhs_dream = [model_marginal_llh_analytic_2x2D(dream['z'], dream['r'], sigma_r, Sigma_0_2D = np.array([[1., 0.], [0., 1.]])) for dream in dreams]\n",
        "\n",
        "# mllhs on ground truth data\n",
        "onetask_mllh = helper.model_marginal_llh_analytic(data_fit['z'], data_fit['r'], sigma_r, Sigma_0=np.eye(2))\n",
        "twotask_mllh = model_marginal_llh_analytic_2x2D(data_fit['z'], data_fit['r'], sigma_r, Sigma_0_2D = np.array([[1., 0.], [0., 1.]]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:21.880Z",
          "iopub.execute_input": "2021-04-07T13:06:21.887Z",
          "shell.execute_reply": "2021-04-07T13:06:42.001Z",
          "iopub.status.idle": "2021-04-07T13:06:41.974Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plot_data_xy_labels(true_data, xylabels)\n",
        "plt.title(\"true data\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "samples = posterior.sample(300)\n",
        "sns.kdeplot(x=samples[:, 0], y=samples[:, 1])\n",
        "plt.scatter(x=samples[:, 0], y=samples[:, 1])\n",
        "plt.title(\"gamma posterior\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:41.984Z",
          "iopub.execute_input": "2021-04-07T13:06:41.992Z",
          "shell.execute_reply": "2021-04-07T13:06:42.672Z",
          "iopub.status.idle": "2021-04-07T13:06:42.690Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "plt.subplot(3,1,1)\n",
        "plt.hist(onetask_mllhs_dream,100)\n",
        "plt.axvline(onetask_mllh, color='gray', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(np.mean(onetask_mllhs_dream), color='lightblue', linestyle='dashed', linewidth=1)\n",
        "plt.xlabel(\"mllh value, true (black dashed), avg (blue dashed)\")\n",
        "plt.ylabel(\"occurences\")\n",
        "\n",
        "plt.hist(twotask_mllhs_dream,100)\n",
        "plt.axvline(twotask_mllh, color='k', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(np.mean(twotask_mllhs_dream), color='darkblue', linestyle='dashed', linewidth=1)\n",
        "plt.title(\"both tasks, 2 task (dark), 1 task (light)\")\n",
        "\n",
        "plt.subplot(3,2,3)\n",
        "plt.hist(onetask_mllhs_dream,100)\n",
        "plt.axvline(onetask_mllh, color='k', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(np.mean(onetask_mllhs_dream), color='b', linestyle='dashed', linewidth=1)\n",
        "plt.xlabel(\"mllh value, true (black dashed), avg (blue dashed)\")\n",
        "plt.ylabel(\"occurences\")\n",
        "plt.title(\"1 x 2D task\")\n",
        "\n",
        "plt.subplot(3,2,4)\n",
        "plt.hist(twotask_mllhs_dream,100)\n",
        "plt.axvline(twotask_mllh, color='k', linestyle='dashed', linewidth=1)\n",
        "plt.axvline(np.mean(twotask_mllhs_dream), color='b', linestyle='dashed', linewidth=1)\n",
        "plt.title(\"2 x 2D task\")\n",
        "\n",
        "plt.subplot(3,3,7)\n",
        "plt.plot([\"1x2D\",\"2x2D\"],[onetask_mllh, twotask_mllh])\n",
        "plt.plot([\"1x2D\",\"2x2D\"],[np.mean(onetask_mllhs_dream), np.mean(twotask_mllhs_dream)])\n",
        "plt.legend([\"true\",\"avg dream\"])\n",
        "\n",
        "plt.subplot(3,3,8)\n",
        "plt.bar([\"1x2D\",\"2x2D\"],[onetask_mllh, twotask_mllh])\n",
        "plt.title(\"mllh on true data\")\n",
        "\n",
        "plt.subplot(3,3,9)\n",
        "plt.bar([\"1x2D\",\"2x2D\"],[np.mean(onetask_mllhs_dream), np.mean(twotask_mllhs_dream)])\n",
        "plt.title(\"avg mllh on dream data\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:42.701Z",
          "iopub.execute_input": "2021-04-07T13:06:42.707Z",
          "shell.execute_reply": "2021-04-07T13:06:43.681Z",
          "iopub.status.idle": "2021-04-07T13:06:43.693Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#num_subplots = len(dreams)\n",
        "num_subplots = 5\n",
        "plt.figure(figsize=(15,10))\n",
        "for i in range(num_subplots):\n",
        "    plt.subplot(num_subplots, num_subplots,i+1)\n",
        "    helper.plot_data(dreams[i], labels=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:43.704Z",
          "iopub.execute_input": "2021-04-07T13:06:43.711Z",
          "shell.execute_reply": "2021-04-07T13:06:44.154Z",
          "iopub.status.idle": "2021-04-07T13:06:44.166Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#num_subplots = len(dreams)\n",
        "num_subplots = 5\n",
        "plt.figure(figsize=(15,10))\n",
        "for i in range(num_subplots):\n",
        "    plt.subplot(num_subplots, num_subplots,i+1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:06:44.177Z",
          "iopub.execute_input": "2021-04-07T13:06:44.184Z",
          "shell.execute_reply": "2021-04-07T13:06:44.453Z",
          "iopub.status.idle": "2021-04-07T13:06:44.460Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points = data_fit\n",
        "plt.scatter(points['z'].T[0],points['z'].T[1])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:13:04.630Z",
          "iopub.execute_input": "2021-04-07T13:13:04.641Z",
          "shell.execute_reply": "2021-04-07T13:13:04.714Z",
          "iopub.status.idle": "2021-04-07T13:13:04.724Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points = data_x\n",
        "plt.scatter(points['z'].T[0],points['z'].T[1])\n",
        "\n",
        "points = data_EM\n",
        "plt.scatter(points['z'].T[0],points['z'].T[1])\n",
        "\n",
        "points = dreams[0]\n",
        "plt.scatter(points['z'].T[0],points['z'].T[1],alpha = 0.5)\n",
        "\n",
        "plt.legend([\"task 1\", \"EM contents\", \"dreamed\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-04-07T13:18:58.702Z",
          "iopub.execute_input": "2021-04-07T13:18:58.709Z",
          "shell.execute_reply": "2021-04-07T13:18:58.843Z",
          "iopub.status.idle": "2021-04-07T13:18:58.850Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "argv": [
        "C:/Users/david/Anaconda3\\python.exe",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}